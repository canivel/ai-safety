# Model Diffing for Sycophancy Research
# Requirements for Gemma 2 2B Base vs Instruct Cross-Coder Analysis
# Optimized for Google Colab (free tier compatible with Gemma 2 2B)

# Core Deep Learning
torch>=2.1.0
transformers>=4.40.0
accelerate>=0.25.0
safetensors>=0.4.0

# Interpretability Libraries
transformer_lens>=2.0.0
nnsight>=0.2.0
sae_lens>=0.4.0

# For Cross-Coder / dictionary_learning
# Clone from: https://github.com/saprmarks/dictionary_learning
# Or install: pip install dictionary-learning

# Hugging Face
huggingface_hub>=0.20.0
datasets>=2.16.0

# Analysis & Visualization
numpy>=1.24.0
pandas>=2.0.0
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.18.0
scikit-learn>=1.3.0

# Jupyter Support
jupyterlab>=4.0.0
ipywidgets>=8.0.0
tqdm>=4.66.0

# NLP Metrics (for sycophancy measurement)
nltk>=3.8.0
textblob>=0.17.0

# Utilities
einops>=0.7.0
jaxtyping>=0.2.0
typing_extensions>=4.8.0
pyyaml>=6.0.0
python-dotenv>=1.0.0

# Optional: For larger experiments
# bitsandbytes>=0.41.0  # For 8-bit quantization
# flash-attn>=2.4.0     # For faster attention (requires CUDA)
